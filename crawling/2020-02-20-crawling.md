## web crawling
1. requests : json : 동적페이지(URL 변경 없이 데이터를 수정 및 추가)
2. requests : html : 정적페이지(URL 변경 으로 데이터를 수정 및 추가)
3. selenium : web browser : 1,2 번 방법을 사용하지 못할때 사용, 브라우저를 직접 조작

## json
- 문자열 데이터를 dict로 바꿔서 저장

## 크롤링 절차
1. 웹서비스 분석 : URL 분석하기, 
2. request, response 하기 : json을 얻음
3. 문자열 json 데이터를 dict로 파싱후 데이터 프레임으로 생성

## 정규화 : Normalization
- `z = (x - min(x)) / (max(x) - min(x))`
- 같은 기준을 놓고 비교하기 위한 절차

## API로 날씨 정보 가져오기
- darksky.net 서비스를 이용
- restAPI : 키값을 감춰서 깔끔한 URL을 만들수 있다. 

## 직방 데이터 크롤링
- 동이름을 입력하여 아파트 메물을 데이터 프레임으로 만드는 작업
- `%%writefile` -> 모듈화 하여 저장

## robots.txt
- 각 도메인 별로 접근 권한 등의 규칙을 저장해 놓은 파일
> 예) User-agent : *
>    Allow : / 


